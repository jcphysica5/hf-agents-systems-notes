{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Agent Library\n",
    "\n",
    "Building a minimal agent from scratch — no framework, just Python.\n",
    "\n",
    "**Reference:** [HF Agents Course — Unit 1: Dummy Agent Library](https://github.com/huggingface/agents-course/blob/main/units/en/unit1/dummy-agent-library.mdx)\n",
    "\n",
    "---\n",
    "### Setup\n",
    "```\n",
    "pip install huggingface_hub\n",
    "```\n",
    "Set your HF token as the environment variable `HF_TOKEN` (or in Colab → Secrets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b70ac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "## You need a token from https://hf.co/settings/tokens, ensure that you select 'read' as the token type. If you run this on Google Colab, you can set it up in the \"settings\" tab under \"secrets\". Make sure to call it \"HF_TOKEN\"\n",
    "# HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "\n",
    "client = InferenceClient(model=\"moonshotai/Kimi-K2.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967360d6",
   "metadata": {},
   "source": [
    "**Kimi-K2.5** is developed by [Moonshot AI](https://www.moonshot.cn/), a Chinese AI research company. It is a large mixture-of-experts (MoE) model with strong instruction-following and reasoning capabilities. We use it here because:\n",
    "\n",
    "- It is available for free on the HF Serverless Inference API with no local setup required\n",
    "- It reliably follows the ReAct format specified in the system prompt\n",
    "- It supports an optional extended-thinking mode (which we disable with `extra_body={\"thinking\": {\"type\": \"disabled\"}}` to keep outputs shorter and more predictable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ccc6c4",
   "metadata": {},
   "source": [
    "## 1. Serverless API — quick smoke test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "077e1458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris\n"
     ]
    }
   ],
   "source": [
    "output = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"The capital of France is\"},\n",
    "    ],\n",
    "    stream=False,\n",
    "    max_tokens=1024,\n",
    "    extra_body={'thinking': {'type': 'disabled'}},\n",
    ")\n",
    "print(output.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb3fb6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (4031191622.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m(this Thought/Action/Observation can repeat N times, you should take several steps when needed. The $JSON_BLOB must be formatted as markdown and only use a SINGLE action at a time.)\u001b[39m\n     ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c8c148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f92eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d21241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7937ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29df220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bac2843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c70f3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Serverless API — quick smoke test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. System prompt — tools + ReAct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"Answer the following questions as best you can. \\\n",
    "You have access to the following tools:\n",
    "\n",
    "get_weather: Get the current weather in a given location\n",
    "\n",
    "The way you use the tools is by specifying a json blob.\n",
    "Specifically, this json should have an `action` key (with the name of the tool to use)\n",
    "and an `action_input` key (with the input to the tool going here).\n",
    "\n",
    "The only values that should be in the \"action\" field are:\n",
    "  get_weather: Get the current weather in a given location,\n",
    "               args: {{\"location\": {{\"type\": \"string\"}}}}\n",
    "\n",
    "example use:\n",
    "  {{ \"action\": \"get_weather\", \"action_input\": {{\"location\": \"New York\"}} }}\n",
    "\n",
    "ALWAYS use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about one action to take. Only one action at a time.\n",
    "Action:\n",
    "```\n",
    "$JSON_BLOB\n",
    "```\n",
    "Observation: the result of the action.\n",
    "... (Thought/Action/Observation can repeat N times)\n",
    "\n",
    "You must always end with:\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Now begin! Reminder to ALWAYS use the exact characters `Final Answer:` when responding.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. First call — spot the hallucination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\",   \"content\": \"What's the weather in London?\"},\n",
    "]\n",
    "\n",
    "output = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    stream=False,\n",
    "    max_tokens=200,\n",
    "    extra_body={\"thinking\": {\"type\": \"disabled\"}},\n",
    ")\n",
    "print(output.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fix: stop before the model invents an Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    max_tokens=150,\n",
    "    stop=[\"Observation:\"],   # stop here so we can inject the real result\n",
    "    extra_body={\"thinking\": {\"type\": \"disabled\"}},\n",
    ")\n",
    "partial = output.choices[0].message.content\n",
    "print(partial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dummy tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Return fake weather data for a location.\"\"\"\n",
    "    return f\"the weather in {location} is sunny with low temperatures.\\n\"\n",
    "\n",
    "print(get_weather(\"London\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Inject real observation and resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_with_obs = [\n",
    "    {\"role\": \"system\",    \"content\": SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\",      \"content\": \"What's the weather in London?\"},\n",
    "    {\"role\": \"assistant\", \"content\": partial\n",
    "                                     + \"Observation:\\n\"\n",
    "                                     + get_weather(\"London\")},\n",
    "]\n",
    "\n",
    "final_output = client.chat.completions.create(\n",
    "    messages=messages_with_obs,\n",
    "    stream=False,\n",
    "    max_tokens=200,\n",
    "    extra_body={\"thinking\": {\"type\": \"disabled\"}},\n",
    ")\n",
    "print(final_output.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Experiment — try a different city or add a second tool\n",
    "\n",
    "Ideas:\n",
    "- Change the city in the user message\n",
    "- Add a `get_time(city)` tool and update the system prompt\n",
    "- Ask a two-step question that requires both tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your experiments here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf-agents-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
